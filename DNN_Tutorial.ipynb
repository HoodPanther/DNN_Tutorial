{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Theano imports\n",
    "import theano\n",
    "theano.config.floatX = 'float32'\n",
    "import theano.tensor as T\n",
    "\n",
    "# Plotting utility\n",
    "from utils import tile_raster_images as tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "The dataset is the mnist digits which is a common toy data set for testing machine learning methods on images. This is a subset of the mnist set which have also been shrunked in size. Let's load them and plot some. In addition to the images, there are also the labels: 0-9 or even-odd.\n",
    "\n",
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = loadmat('small_mnist.mat')\n",
    "\n",
    "# Training data (images, 0-9, even-odd)\n",
    "# Images are stored in a (batch, x, y) array\n",
    "# Labels are integers\n",
    "train_im = data['train_im']\n",
    "train_y = data['train_y'].ravel()\n",
    "train_eo = data['train_eo'].ravel()\n",
    "\n",
    "# Validation data (images, 0-9, even-odd)\n",
    "# Same format as training data\n",
    "valid_im = data['valid_im']\n",
    "valid_y = data['valid_y'].ravel()\n",
    "valid_eo = data['valid_eo'].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 10 of the training images. Rerun this cell to plot new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 6 1 9 7 2 0 7 4 6]\n",
      "Odd-Even: [0 0 1 1 1 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAA+CAYAAAAYjLE4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ea5dc1cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_size = train_im.shape[-1]\n",
    "order = np.random.permutation(train_im.shape[0])\n",
    "ims = tri(train_im[order[:10]].reshape((-1, im_size**2)), (im_size, im_size), (1, 10), (1,1))\n",
    "plt.imshow(ims, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "print('Labels: {}'.format(train_y[order[:10]]))\n",
    "print('Odd-Even: {}'.format(train_eo[order[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline linear classifier\n",
    "Before we spend our precious time setting up and training deep networks on the data, let's see how a simple linear classifier from sklearn can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the classifier to do multinomial classification\n",
    "linear_classifier = LR(solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error on (0-9): 0.9278\n",
      "Validation Error on (0-9): 0.898\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the classifier\n",
    "linear_classifier.fit(train_im.reshape(-1, im_size**2), train_y)\n",
    "print('Training Error on (0-9): {}'.format(linear_classifier.score(train_im.reshape(-1, im_size**2), train_y)))\n",
    "print('Validation Error on (0-9): {}'.format(linear_classifier.score(valid_im.reshape(-1, im_size**2), valid_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training a linear classifier on the Even-Odd labels: train_eo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Deep Nets library\n",
    "If you're just starting off with deep nets and want to quickly try them on a dataset it is probably easiest to start with an existing library rather than writing your own. There are now a bunch of different libraries written for Python. We'll be using Keras which is designed to be easy to use. In matlab, there is the Neural Network Toolbox.\n",
    "\n",
    "Keras documentation can be found here:\n",
    "http://keras.io/\n",
    "\n",
    "We'll do the next most complicated network comparer to linear regression: a two layer network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Import things from Keras Library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected MLP\n",
    "This is a simple network made from two layers. On the Keras documentation page, you can find other nonlinearities under \"Core Layers\".\n",
    "\n",
    "You can add more layers, changes the layers, change the optimizer, or add dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after layer 1: (None, 100)\n",
      "\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.5889 - acc: 0.8267     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.3161 - acc: 0.9066     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.2743 - acc: 0.9198     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.2432 - acc: 0.9290     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.2186 - acc: 0.9359     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1942 - acc: 0.9428     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1722 - acc: 0.9498     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1569 - acc: 0.9524     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1423 - acc: 0.9587     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1291 - acc: 0.9631     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1178 - acc: 0.9674     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1071 - acc: 0.9694     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0998 - acc: 0.9720     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0903 - acc: 0.9740     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0848 - acc: 0.9763     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0774 - acc: 0.9803     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0727 - acc: 0.9805     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0660 - acc: 0.9833     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0618 - acc: 0.9848     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0582 - acc: 0.9847     \n",
      "10000/10000 [==============================] - 0s     \n",
      "1000/1000 [==============================] - 0s     \n",
      "\n",
      "Train loss: 0.0496415880136, train accuracy: 0.989000009894\n",
      "Validation loss: 0.187954966817, validation accuracy: 0.948000013828\n"
     ]
    }
   ],
   "source": [
    "# Create the network!\n",
    "mlp = Sequential()\n",
    "\n",
    "# First fully connected layer\n",
    "mlp.add(Dense(im_size**2, input_shape=(im_size**2,))) # number of hidden units, default is 100\n",
    "mlp.add(Activation('tanh')) # nonlinearity\n",
    "print('Shape after layer 1: {}'.format(mlp.output_shape))\n",
    "\n",
    "# Second fully connected layer with softmax output\n",
    "mlp.add(Dropout(0.0)) # dropout is currently turned off, you may need to train for more epochs if nonzero\n",
    "mlp.add(Dense(10)) # number of targets, 10 for y, 2 for eo\n",
    "mlp.add(Activation('softmax'))\n",
    "\n",
    "# Adam is a simple optimizer, SGD has more parameters and is slower but may give better results\n",
    "#opt = Adam()\n",
    "#opt = RMSprop()\n",
    "opt = SGD(lr=0.1, momentum=0.9, decay=0.0001, nesterov=True)\n",
    "print('')\n",
    "mlp.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "mlp.fit(train_im.reshape(-1, im_size**2), np_utils.to_categorical(train_y), nb_epoch=20, batch_size=100)\n",
    "tr_score = mlp.evaluate(train_im.reshape(-1, im_size**2), np_utils.to_categorical(train_y), batch_size=100)\n",
    "va_score = mlp.evaluate(valid_im.reshape(-1, im_size**2), np_utils.to_categorical(valid_y), batch_size=100)\n",
    "print('')\n",
    "print('Train loss: {}, train accuracy: {}'.format(*tr_score))\n",
    "print('Validation loss: {}, validation accuracy: {}'.format(*va_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional MLP\n",
    "We can also have the first layer be a set of small filters which are convolved with the images.\n",
    "\n",
    "Try different parameters and see what happens. (This network might be slow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after layer 1: (None, 20, 4, 4)\n",
      "Shape after flatten: (None, 320)\n",
      "\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.5487 - acc: 0.8347     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.2599 - acc: 0.9252     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1915 - acc: 0.9442     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1451 - acc: 0.9571     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.1158 - acc: 0.9671     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0932 - acc: 0.9720     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0764 - acc: 0.9779     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0604 - acc: 0.9841     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0480 - acc: 0.9879     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0375 - acc: 0.9926     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0304 - acc: 0.9933     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0254 - acc: 0.9950     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0194 - acc: 0.9981     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0161 - acc: 0.9983     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0132 - acc: 0.9985     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0109 - acc: 0.9998     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0095 - acc: 0.9996     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0081 - acc: 0.9999     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0072 - acc: 1.0000     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s - loss: 0.0066 - acc: 1.0000     \n",
      "10000/10000 [==============================] - 0s     \n",
      "1000/1000 [==============================] - 0s     \n",
      "\n",
      "Train loss: 0.00561035628198, train accuracy: 1.0\n",
      "Validation loss: 0.204669129755, validation accuracy: 0.955000001192\n"
     ]
    }
   ],
   "source": [
    "# Create the network!\n",
    "cnn = Sequential()\n",
    "\n",
    "# First fully connected layer\n",
    "cnn.add(Convolution2D(20, 3, 3, input_shape=(1, im_size, im_size), border_mode='valid', subsample=(2, 2)))\n",
    "cnn.add(Activation('tanh')) # nonlinearity\n",
    "print('Shape after layer 1: {}'.format(cnn.output_shape))\n",
    "\n",
    "# Take outputs and turn them into a vector\n",
    "cnn.add(Flatten())\n",
    "print('Shape after flatten: {}'.format(cnn.output_shape))\n",
    "\n",
    "# Fully connected layer\n",
    "cnn.add(Dropout(0.0)) # dropout is currently turned off, you may need to train for more epochs if nonzero\n",
    "cnn.add(Dense(100)) # number of targets, 10 for y, 2 for eo\n",
    "cnn.add(Activation('tanh'))\n",
    "\n",
    "# Second fully connected layer with softmax output\n",
    "cnn.add(Dropout(0.0)) # dropout is currently turned off, you may need to train for more epochs if nonzero\n",
    "cnn.add(Dense(10)) # number of targets, 10 for y, 2 for eo\n",
    "cnn.add(Activation('softmax'))\n",
    "\n",
    "# Adam is a simple optimizer, SGD has more parameters and is slower but may give better results\n",
    "#opt = Adam()\n",
    "#opt = RMSprop()\n",
    "opt = SGD(lr=0.1, momentum=0.9, decay=0.0001, nesterov=True)\n",
    "print('')\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "cnn.fit(train_im[:, np.newaxis, ...], np_utils.to_categorical(train_y), nb_epoch=20, batch_size=100)\n",
    "tr_score = cnn.evaluate(train_im[:, np.newaxis, ...], np_utils.to_categorical(train_y), batch_size=100)\n",
    "va_score = cnn.evaluate(valid_im[:, np.newaxis, ...], np_utils.to_categorical(valid_y), batch_size=100)\n",
    "print('')\n",
    "print('Train loss: {}, train accuracy: {}'.format(*tr_score))\n",
    "print('Validation loss: {}, validation accuracy: {}'.format(*va_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
